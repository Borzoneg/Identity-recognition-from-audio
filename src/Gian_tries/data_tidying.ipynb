{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data tidying and Feature extraction\n",
    "Here I am trying to extract different features from the .wav files and use them instead of the file, these are what I choose as features:\n",
    "\n",
    "### 1. Mel-Frequency Cepstral Coefficients (MFCCs):\n",
    "\n",
    "MFCCs are coefficients that represent the short-term power spectrum of a sound signal. The process involves the following steps:\n",
    "\n",
    "- **Frame the Signal:** The audio signal is divided into short frames.\n",
    "- **Apply Discrete Fourier Transform (DFT):** The power spectrum of each frame is calculated.\n",
    "- **Apply Mel Filterbank:** The power spectrum is passed through a set of filters designed to mimic the human ear's sensitivity to different frequencies.\n",
    "- **Take the Logarithm:** The logarithm of the powers is taken, emphasizing lower frequencies.\n",
    "- **Apply Discrete Cosine Transform (DCT):** The result is transformed using the DCT, producing a set of coefficients.\n",
    "\n",
    "The MFCCs capture important spectral characteristics of the audio signal and are commonly used in speech and audio processing.\n",
    "\n",
    "### 2. Chroma Feature:\n",
    "\n",
    "Chroma features represent the 12 different pitch classes as features (C, C#, D, D#, E, F, F#, G, G#, A, A# and B), capturing tonal content. The steps to compute chroma features include:\n",
    "\n",
    "- **Frame the Signal:** Similar to MFCCs, the audio signal is divided into short frames.\n",
    "- **Calculate Short-Time Fourier Transform (STFT):** Compute the magnitude spectrum of each frame.\n",
    "- **Apply Chroma Filterbank:** Use filters designed to capture energy in each of the 12 pitch classes.\n",
    "- **Sum across Octaves:** Sum the energy within each pitch class across different octaves.\n",
    "\n",
    "Chroma features are useful for analyzing musical content and are often used in tasks such as music genre classification.\n",
    "\n",
    "### 3. Spectral Contrast:\n",
    "\n",
    "Spectral contrast measures the difference in amplitude between peaks and valleys in the spectrum. The steps are as follows:\n",
    "\n",
    "- **Divide the Spectrum:** Divide the spectrum into frequency bins.\n",
    "- **Calculate the Peak and Valley Levels:** Identify the peak and valley magnitudes within each bin.\n",
    "- **Compute Contrast:** Contrast is computed as the difference between the peak and valley magnitudes.\n",
    "\n",
    "Spectral contrast provides information about the texture and timbre of the audio signal.\n",
    "\n",
    "### 4. Spectral Centroid:\n",
    "\n",
    "Spectral centroid indicates the center of mass of the spectrum. It represents the \"center of gravity\" of the frequency distribution. The steps are:\n",
    "\n",
    "- **Compute the Spectrum:** Calculate the magnitude spectrum of the signal.\n",
    "- **Calculate the Centroid:** The centroid is the weighted mean of the frequencies, where the weights are the magnitudes.\n",
    "\n",
    "Spectral centroid is often used to characterize the \"brightness\" of the sound.\n",
    "\n",
    "### 5. Spectral Bandwidth:\n",
    "\n",
    "Spectral bandwidth measures the width of the spectrum. It indicates the spread of frequencies around the spectral centroid. The steps are:\n",
    "\n",
    "- **Compute the Spectrum:** Calculate the magnitude spectrum of the signal.\n",
    "- **Calculate the Bandwidth:** Bandwidth is computed as the square root of the second central moment of the spectrum.\n",
    "\n",
    "Spectral bandwidth provides information about the range of frequencies present in the signal.\n",
    "\n",
    "These features collectively capture different aspects of the audio signal, providing valuable information for various audio processing tasks, including machine learning-based audio analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "The way we extract data from the wav is `_, wav = wavfile.read(file_path)`, so we are extracting only the audio data and not the sample rate, the problem is that if the sliced one is not sliced properly, with the same duration, the sample rate can be fucked and the audio data is referred to a different sample rate, introducing error. I think is worth a shot understand this.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
